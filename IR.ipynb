{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHVyBO0fLcdz",
        "outputId": "2fe162b0-5a09-4fa5-b450-ce698f701c1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id 1HSh3wkhjgMdjtrkwQUPszRKo_KFF-kGk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HSh3wkhjgMdjtrkwQUPszRKo_KFF-kGk\n",
            "To: /content/human_data.txt\n",
            "\r0.00B [00:00, ?B/s]\r5.55MB [00:00, 175MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfyX9hNC3sZc",
        "outputId": "ee588727-9e39-4cb8-9ed4-3cc33a7bcd6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "df = pd.read_csv('human_data.txt', sep=\"\\t\")\n",
        "\"\"\"df is the variable that stores all our data ( DNA strings here )\"\"\"\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4380"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvl_6CDh3saB",
        "outputId": "3af0a4a9-0920-42df-dfa5-f9aeae445b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCA...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ATGAACGAAAATCTGTTCGCTTCATTCATTGCCCCCACAATCCTAG...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ATGCAACAGCATTTTGAATTTGAATACCAGACCAAAGTGGATGGTG...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sequence  class\n",
              "0  ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCA...      4\n",
              "1  ATGAACGAAAATCTGTTCGCTTCATTCATTGCCCCCACAATCCTAG...      4\n",
              "2  ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...      3\n",
              "3  ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...      3\n",
              "4  ATGCAACAGCATTTTGAATTTGAATACCAGACCAAAGTGGATGGTG...      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se0XLymN3saR"
      },
      "source": [
        "def find_shingles(string, k):\n",
        "    \"\"\"\n",
        "    <h5> A function to find the shingles of our data \n",
        "    <ol> It takes in 2 inputs :\n",
        "    <li> The string , from which it will generate the shingles </li>\n",
        "    <li> The length of each shingle. It will generate a k-shingle and return it </li>\n",
        "    </ol>\n",
        "    It returns all the shingles from its string input\n",
        "    </h5>\n",
        "    \"\"\"\n",
        "    shingle = set()\n",
        "    for i in range(len(string)-k+1):\n",
        "        shingle.add(string[i:i+k])\n",
        "    return shingle\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EF123-r3sah"
      },
      "source": [
        "y = df['class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbXgM9KZ3sas"
      },
      "source": [
        "k = 5\n",
        "\"\"\"This is our global variable for the shingle length. We can change it and make k-shingles accordingly\"\"\"\n",
        "def doc_shingles(df, k):\n",
        "    \"\"\"\n",
        "    <h5>The main function to create the shingles of all our documents\n",
        "    <ul><li> It takes in dataframe , and separates the df into individual document. </li>\n",
        "    <li> For each document, it takes in each string and passes it onto the function <i>find_shingles</i> to get the shingle.</li> \n",
        "    <li> It also checks to ensure that all the shingles are made correctly and there's no shingle which is empty.</li>\n",
        "    <li> Once done that, we once again add all the shingles of each document together.</li>\n",
        "    <li> Finally , we add all the documents back into an array and return this </li>\n",
        "    </ul> </h5>\n",
        "    \"\"\"\n",
        "    shingle_arr = list()\n",
        "    shingle_set = set()\n",
        "    invalid_doc = []\n",
        "    for i in range(len(df)):\n",
        "        shingle = find_shingles(df.loc[i]['sequence'], k)\n",
        "        if len(shingle) == 0:\n",
        "            invalid_doc.append(i)\n",
        "        for i in shingle:\n",
        "            shingle_set.add(i)\n",
        "        shingle_arr.append(shingle)\n",
        "    return shingle_arr, shingle_set\n",
        "\n",
        "shingle_arr,shingle_set = doc_shingles(df, k)     \n",
        "#len(df), len(shingle_arr), len(shingle_set), invalid_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMAg_SK13sbD",
        "outputId": "a53b9bfe-9275-4387-b1c8-1ee7066e0f61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "def gen_matrix(df,shingle_set,shingle_arr):\n",
        "    \"\"\"\n",
        "    <h5>Once we have shingled our documents, we proceed ahead to make our matrix. This function takes in the shingled set and array and generates matrix from them.\n",
        "    <br><br>\n",
        "    It finally will return the generated matrix.</h5>\n",
        "    \"\"\"\n",
        "    d = dict()\n",
        "    for shingle in shingle_set:\n",
        "        d[shingle]=list()\n",
        "    for i in range(len(df)):\n",
        "        doc_shingle = shingle_arr[i]\n",
        "        for global_shingle in shingle_set:\n",
        "            if global_shingle in doc_shingle:\n",
        "                d[global_shingle].append(1)\n",
        "                #print(global_shingle, d[global_shingle])\n",
        "            else:\n",
        "                d[global_shingle].append(0)\n",
        "    mat = []\n",
        "    for i in d.keys():\n",
        "        mat.append(d[i])\n",
        "    mat = np.array(mat)\n",
        "    return mat, doc_shingle\n",
        "\n",
        "matrix, doc_shingle= gen_matrix(df,shingle_set,shingle_arr)\n",
        "\"\"\"The variable that stores our matrix after the shingling is complete. \n",
        "We later on use this to generate our signature matrix.\"\"\"\n",
        "matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1247, 4380)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Nq72b03sbY",
        "outputId": "d7f6e0f4-1e1a-48d6-82a6-5f6117b6a138",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_perm = 50\n",
        "\"\"\"Our global variable to store the number of permutations of the matrix that we will use to convert the matrix M into signature matrix.\n",
        "This also defines the size of our signature matrix.\"\"\"    \n",
        "def gen_permute(n, matrix):\n",
        "    \"\"\"\n",
        "    <h5>\n",
        "    <ul>\n",
        "    <li>We generate the permutation matrix for minhashing using the number of permutations given to us.<br></li>\n",
        "    <li>By default this value is 50, and we can change this asd required.<br></li>\n",
        "    <li>It will return us the permutations array consisting of the various permutations that we will work with upon the matrix M during minHashing.</li></ul>\n",
        "    </h5>\n",
        "    \"\"\"\n",
        "    perm_arr = []\n",
        "    for i in range(n_perm):\n",
        "        a = np.arange(len(matrix))\n",
        "        random.shuffle(a)\n",
        "        perm_arr.append(a)\n",
        "    return perm_arr\n",
        "\n",
        "permute_array = gen_permute(n_perm, matrix)\n",
        "\"\"\"Our global variable to store the permutations that we will work upon to convert the matrix M into signature matrix\"\"\"\n",
        "len(permute_array), len(permute_array[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 1247)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5V5oBg2Cao5"
      },
      "source": [
        "def find(indx):\n",
        "    \"\"\"\n",
        "    <h5>\n",
        "    A function to locate an index within our signature matrix . \n",
        "    </h5>\n",
        "    \"\"\"\n",
        "    indx = np.array(indx).argsort()\n",
        "    sig = np.array([float('inf') for _ in range(len(mat[0]))])\n",
        "    for i in range(len(indx)):\n",
        "        matches = [ind for ind in range(len(mat[indx[i]])) if mat[indx[i]][ind] == 1]\n",
        "        for index in matches:\n",
        "            sig[index] = min(i, sig[index])\n",
        "    return sig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGFZBWFg3sbj",
        "scrolled": true,
        "outputId": "4af8e08d-4591-4e21-cf5a-126d370b5561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "def gen_sig_matrix(perm_arr,mat):\n",
        "    \"\"\"\n",
        "    <h5> <ul>A function to generate the signature matrix\n",
        "    <li>For each row in permutation array, we take in the given set of rows from matrix M and generate an array.</li>\n",
        "    <li>We proceed to hash it and keep the minimum of the hash values for each row.</li>\n",
        "    <li>Finally , we append all these rows to signature array and return it as the completed signature matrix.</li>\n",
        "    </ul>\n",
        "    </h5>\n",
        "    \"\"\"\n",
        "    sig_mat = list()\n",
        "    l = 0\n",
        "    for indx in perm_arr:\n",
        "        indx = np.array(indx).argsort()\n",
        "        sig = np.array([float('inf') for _ in range(len(mat[0]))])\n",
        "        for i in range(len(indx)):\n",
        "            matches = [ind for ind in range(len(mat[indx[i]])) if mat[indx[i]][ind] == 1]\n",
        "            for index in matches:\n",
        "                sig[index] = min(i, sig[index])\n",
        "        if l%10 == 0:\n",
        "            print(l)\n",
        "        l+=1\n",
        "        sig_mat.append(sig)\n",
        "    return sig_mat, perm_arr\n",
        "    \n",
        "signature_mat, perm_arr = gen_sig_matrix(permute_array, matrix)\n",
        "\"\"\"Our variable to store the signature matrix. We get this by using the permutation array on our matrix M\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Our variable to store the signature matrix. We get this by using the permutation array on our matrix M'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeMLQBBWCapR"
      },
      "source": [
        "rows = 3    #num of rows per band\n",
        "\"\"\"Our global variable to store the number of rows for each band\"\"\"\n",
        "n_buckets = 15  #number of buckets\n",
        "\"\"\"The global variable to store the number of maximum buckets we will sort the strings into\"\"\"\n",
        "\n",
        "def lsh(sig_mat,r,n):\n",
        "    \"\"\"\n",
        "    <h5>\n",
        "    The function for implement LSH ( Locality Sensitive Hashing ) :\n",
        "    <ul>\n",
        "    <li>We use the signature matrix as our input here.</li>\n",
        "    <li> We run a hash function , which is the sum of the numbers to hash our values into multiple buckets </li>\n",
        "    <li> Finally , we return the buckets to our user , which contain the list of possible candidate pairs which can be similar</li>\n",
        "    </ul>\n",
        "    </h5>\n",
        "    \"\"\"\n",
        "    sig_mat = np.array(sig_mat)\n",
        "    buckets = [[] for _ in range(n)]\n",
        "    summ = []\n",
        "    for i in range(0, len(sig_mat)-r+1, r):\n",
        "        band = sig_mat[i:i+r]\n",
        "        for doci in range(len(band[0])):\n",
        "            try:\n",
        "                buckets[int(np.sum(band[:, doci])%len(buckets))].append(doci)\n",
        "            except:\n",
        "                print(\"invalid doc:\", doci)\n",
        "    return buckets\n",
        "buckets = lsh(signature_mat,rows,n_buckets)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_gqcFYVCapd",
        "outputId": "17ae7b98-dc73-475c-83ce-c2dcf8668cf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCA\n",
        "query = df.iloc[0][\"sequence\"]\n",
        "\"\"\"Our query , for which we search in the dataset \"\"\"\n",
        "q_class = df.iloc[0][\"class\"]\n",
        "\"\"\"Our query class, to which our given query belongs to \"\"\"\n",
        "shingles = find_shingles(query, k)\n",
        "query, q_class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCATACTCCTTACACTATTCCTCATCACCCAACTAAAAATATTAAACACAAACTACCACCTACCTCCCTCACCAAAGCCCATAAAAATAAAAAATTATAACAAACCCTGAGAACCAAAATGAACGAAAATCTGTTCGCTTCATTCATTGCCCCCACAATCCTAG',\n",
              " 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGsfrcVrCaqO"
      },
      "source": [
        "def similarity(s1, s2, k):\n",
        "    \"\"\"\n",
        "    <h5> A function to compare 2 given k shingles. We get the jaccard similarity score of the two here </h5>\n",
        "    \"\"\"\n",
        "    s1 = find_shingles(s1, k)\n",
        "    s2 = find_shingles(s2, k)\n",
        "    return len(s1&s2)/len(s1|s2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGBTwME4CaqX",
        "outputId": "b2bffdb3-390e-465d-8580-3c445389f95a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "top_n = 5\n",
        "\"\"\"We define this variable to store the number of top results that we would give as output.\"\"\"\n",
        "def search(query, q_class, doc_shingle, perm_arr, r, top_n):\n",
        "    \"\"\"\n",
        "    <h5>\n",
        "    A function that will take in the <ul>\n",
        "    <li>The search query</li><li>The search query class</li>\n",
        "    <li>Number of maximum relevant results to be shown</li></ul>\n",
        "     and then print the output results , along with their similarity and the string at which they were found.</h5>\n",
        "    \"\"\"\n",
        "    query_d = dict()\n",
        "    \"\"\"Generate the shingles of our query string\"\"\"\n",
        "    for shingle in shingle_set:\n",
        "        query_d[shingle]=list()\n",
        "    #Generate the shingles of our query string  \n",
        "    for global_shingle in shingle_set:\n",
        "        if global_shingle in doc_shingle:\n",
        "            query_d[global_shingle].append(1)\n",
        "        else:\n",
        "            query_d[global_shingle].append(0)\n",
        "    query_mat = []\n",
        "    \"\"\"Generate the matrix for our given query string\"\"\"\n",
        "    for i in query_d.keys():\n",
        "        query_mat.append(query_d[i])\n",
        "    query_mat = np.array(query_mat)\n",
        "    #Generate the matrix M for our given query\n",
        "    query_sig_mat = list()\n",
        "    \"\"\"Signature matrix of our query\"\"\"\n",
        "    for indx in perm_arr:\n",
        "        indx = np.array(indx).argsort()\n",
        "        sig = np.array([float('inf') for _ in range(len(query_mat[0]))])\n",
        "        for i in range(len(indx)):\n",
        "            matches = [ind for ind in range(len(query_mat[indx[i]])) if query_mat[indx[i]][ind] == 1]\n",
        "            for index in matches:\n",
        "                sig[index] = min(i, sig[index])\n",
        "        query_sig_mat.append(sig)    \n",
        "    #Successfully generated signature matrix \n",
        "    result_bucket = []\n",
        "    \"\"\"The buckets for our result\"\"\"\n",
        "    for i in range(0, len(query_sig_mat)-r+1, r):\n",
        "        band = query_sig_mat[i:i+r]\n",
        "        result_bucket.append(sum(sum(band))%len(buckets))\n",
        "    result_doc = []\n",
        "    for i in result_bucket:\n",
        "        for j in buckets[int(i)]:\n",
        "            result_doc.append([similarity(df.iloc[j][\"sequence\"], query, k), j])\n",
        "    result = np.argsort([i[0] for i in result_doc])[::-1][:top_n]\n",
        "    #Generated the result. Now we move to printing them.\n",
        "    print(\"Query:   \", query[:80], \"\\tClass:\", q_class)\n",
        "    print()\n",
        "    for i in result:\n",
        "        print(\"Similarity:\", result_doc[i][0], \"\\tClass:\", df.iloc[result_doc[i][1]]['class'], \"Doc ID: \", result_doc[i][1])\n",
        "        print(\"Document:\", df.iloc[result_doc[i][1]]['sequence'][:100])\n",
        "        print()\n",
        "\n",
        "search(query, q_class, doc_shingle, perm_arr, rows, top_n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Query:    ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCATACTCCTTACACTATTCCTCATCACCCAACTAAA \tClass: 4\n",
            "\n",
            "Similarity: 1.0 \tClass: 4 Doc ID:  0\n",
            "Document: ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCATACTCCTTACACTATTCCTCATCACCCAACTAAAAATATTAAACACAAACTACC\n",
            "\n",
            "Similarity: 1.0 \tClass: 4 Doc ID:  0\n",
            "Document: ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCATACTCCTTACACTATTCCTCATCACCCAACTAAAAATATTAAACACAAACTACC\n",
            "\n",
            "Similarity: 1.0 \tClass: 4 Doc ID:  0\n",
            "Document: ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCATACTCCTTACACTATTCCTCATCACCCAACTAAAAATATTAAACACAAACTACC\n",
            "\n",
            "Similarity: 1.0 \tClass: 4 Doc ID:  0\n",
            "Document: ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCATACTCCTTACACTATTCCTCATCACCCAACTAAAAATATTAAACACAAACTACC\n",
            "\n",
            "Similarity: 1.0 \tClass: 4 Doc ID:  0\n",
            "Document: ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCATACTCCTTACACTATTCCTCATCACCCAACTAAAAATATTAAACACAAACTACC\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}